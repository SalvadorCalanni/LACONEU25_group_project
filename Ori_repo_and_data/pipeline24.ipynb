{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "* Trains over all the pairs of tasks and saves each network on a specified directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alltask trainer\n",
    "import train\n",
    "from analysis import performance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tools\n",
    "import numpy as np\n",
    "from task import generate_trials, rule_name, get_dist\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disable GPU\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure TF to use single thread\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "\n",
    "def trainpair(task1,task2,hnodes=32,netfolder=\"networks/\"):\n",
    "    netname = \"_\".join([\"laconeu\",task1,task2,str(hnodes)])\n",
    "    train.train(model_dir=netfolder+netname, \n",
    "            hp={'learning_rate': 0.001, \n",
    "                'n_rnn': hnodes,#512, 16384,8192,1024\n",
    "                # 'w_rec_init': 'randgauss',#'randortho'\n",
    "                # 'b_rec_init': 'uniform',\n",
    "                'rule_strength': 1.0,\n",
    "                'no_rule': False,\n",
    "                'target_perf':0.8,\n",
    "                'activation': 'softplus',\n",
    "                'alpha':0.2},\n",
    "            ruleset='all',\n",
    "            rule_trains = [task1,task2],\n",
    "            trainables='all')#,trainables='bias')\n",
    "\n",
    "\n",
    "tasks = ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "            'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "            'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo']\n",
    "excluded = ['dm1', 'dm2', 'contextdm1', 'contextdm2','multidm']\n",
    "\n",
    "# pair task iteration\n",
    "counter = 0 \n",
    "for i in range(len(tasks)):\n",
    "    for j in range(i+1,len(tasks)):\n",
    "        if \"SLURM_ARRAY_TASK_ID\" in os.environ and counter != int(os.environ[\"SLURM_ARRAY_TASK_ID\"]):\n",
    "            counter+=1\n",
    "            continue\n",
    "        print(\"SLURM_ARRAY_TASK_ID\" in os.environ)\n",
    "        print(counter)\n",
    "        print(tasks[i],tasks[j])\n",
    "        counter+=1\n",
    "        trainpair(tasks[i],tasks[j],hnodes=24,netfolder=\"../networks_24/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "* Evaluates the network on the trained tasks and a noise task\n",
    "* Saves the results as a dictionary.\n",
    "\n",
    "* Proposal:\n",
    "  * Change the dictionary save to indvidual files for each task network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass arbitrary inputs to the trained model\n",
    "from network import Model\n",
    "import tensorflow as tf\n",
    "from task import generate_trials, rule_name, get_dist\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def stimulateTrainedModel(model_dir, n_rep = 16, mode='test'):\n",
    "    hp = tools.load_hp(model_dir)\n",
    "    hp_copy = copy.deepcopy(hp)\n",
    "    hp_copy['rules'].append('random')\n",
    "    model = Model(model_dir, hp)\n",
    "    \n",
    "    output_dict = {rn: None for rn in hp_copy['rules']}\n",
    "    with tf.Session() as sess:\n",
    "        model.restore()\n",
    "        rules_ = copy.deepcopy(hp_copy['rules'])\n",
    "        for rule_test in rules_:\n",
    "            batch_size_test_rep = int(hp_copy['batch_size_test']/n_rep)\n",
    "            rep_mat = {'x':[], 'h':[], 'y_hat':[]}\n",
    "            for i_rep in range(n_rep):\n",
    "                # trial = generate_trials(rule, hp, mode='test')\n",
    "                trial = generate_trials(rule_test, hp_copy, mode, batch_size=batch_size_test_rep, \n",
    "                                        rule_strength=hp_copy['rule_strength'], no_rule=hp_copy['no_rule'])\n",
    "                feed_dict = tools.gen_feed_dict(model, trial, hp_copy)\n",
    "                x = trial.x\n",
    "                h, y_hat = sess.run([model.h, model.y_hat], feed_dict=feed_dict)\n",
    "                \n",
    "                # x_flat = x.reshape(-1, x.shape[2])\n",
    "                # h_flat = h.reshape(-1, h.shape[2])\n",
    "                # y_hat_flat = y_hat.reshape(-1, y_hat.shape[2])\n",
    "\n",
    "                rep_mat['x'].append(x)\n",
    "                rep_mat['h'].append(h)\n",
    "                rep_mat['y_hat'].append(y_hat)\n",
    "                \n",
    "            \n",
    "            # for key in rep_mat.keys():\n",
    "            #     rep_mat[key] = np.concatenate(rep_mat[key])\n",
    "            output_dict[rule_test] = rep_mat\n",
    "                \n",
    "    return output_dict\n",
    "\n",
    "all_mods = {}\n",
    "for model_dir in os.listdir('../networks_24/'):\n",
    "    output_dict = stimulateTrainedModel(model_dir, n_rep=4, mode='test')\n",
    "    all_mods[model_dir] = output_dict\n",
    "\n",
    "#save the stimulation results for each model\n",
    "np.save('mods_24.npy', all_mods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOI computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thoi\n",
    "from thoi.measures.gaussian_copula import multi_order_measures, nplets_measures\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "\n",
    "model_dirs = os.listdir(\"../networks_24/\")\n",
    "\n",
    "out = np.load('mods_24.npy', allow_pickle=True).item()\n",
    "out.keys()\n",
    "\n",
    "# join and organize the data\n",
    "alldata = {}\n",
    "for model in model_dirs:\n",
    "    modelh = {}\n",
    "    for task in out[model].keys():\n",
    "        #print(f'{model}_{task}')\n",
    "        hlist = []\n",
    "        for i in range(4):\n",
    "            hmat = out[model][task]['h'][i]\n",
    "            hjoinmatrix = np.swapaxes(hmat[:,:,:],0,1).reshape(-1,hmat.shape[-1]).T\n",
    "            hlist.append(hjoinmatrix)\n",
    "        allh = np.concatenate(hlist, axis=1)\n",
    "        #print(task, allh.shape)\n",
    "        modelh[task] = allh\n",
    "    alldata[model] = modelh\n",
    "shorterlength = min([alldata[model][task].shape[1] for model in model_dirs for task in alldata[model].keys()])\n",
    "\n",
    "\n",
    "all_meanhoi = []\n",
    "\n",
    "for model in model_dirs:\n",
    "    for task in alldata[model].keys():\n",
    "        print(model, task, alldata[model][task].shape)\n",
    "        htensor = torch.tensor(alldata[model][task].T, dtype=torch.float32, device='cpu')\n",
    "        hoidata = multi_order_measures(alldata[model][task][:,:shorterlength].T, min_order=1, max_order=6)\n",
    "        meanhoi = hoidata.groupby('order').mean()[[\"o\", \"s\", \"tc\", \"dtc\"]]\n",
    "        # Add model and task columns\n",
    "        meanhoi['model'] = model\n",
    "        meanhoi['task'] = task\n",
    "        all_meanhoi.append(meanhoi)\n",
    "\n",
    "# Concatenate all meanhoi dataframes\n",
    "concatenated_meanhoi = pd.concat(all_meanhoi)\n",
    "#save the concat dataframe\n",
    "concatenated_meanhoi = concatenated_meanhoi.reset_index()\n",
    "concatenated_meanhoi.to_csv('concatenated_meanhoi_trimmed_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
